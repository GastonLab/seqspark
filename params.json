{
  "name": "Seqspark",
  "tagline": "",
  "body": "# SeqSpark Manual\r\n\r\nZhang Di & Suzanne M. Leal\r\n\r\n[TOC]\r\n\r\n## Introduction\r\n\r\nSeqSpark analyzes large-scale genotype data both in the sense of sample size and of number of variants, usually generated from Whole-Genome-Sequencing (WGS) or Exome-Sequencing (ES) project. In this manual, we will describe its functionalities in data quality control and association testing.\r\n\r\n### Prerequisites\r\n\r\nSince SeqSpark is based on Apache Spark, so to use it in any non-trivial situation you need a running Spark cluster, either provided by your organization or built by yourself. If you want to build a Spark cluster yourself, please refer to [Hadoop](https://hadoop.apache.org/) and [Spark](http://spark.apache.org). If you do not have proper hardware onsite, you may want to setup a cloud environment in AWS, for which we provide a template configuration. We also provide a local Spark configuration for you to play with. Please do not run anything except the demos in the local configuration.\r\n\r\nTo build SeqSpark from source, you need `sbt` and `gfortran` installed.\r\n\r\n### Getting Started\r\n\r\nIn a HOCON format configuration file, you specify the paths of the input genotype file (VCF) and a PED-like phenotype file, and the pipeline with its parameters you want to run. HOCON is an abbreviation for Human-Optimized-Config-Object-Notation. As the name suggested, it is very intuitive to understand and easy to use. Please refer to Examples and Specification for more details. To minimize your typing, we embedded reasonable defaults for all the parameters also in a HOCON file which comes with SeqA. You only need to configure the different parts in your own file. With the configuration file and all the necessary input files ready, you can run your analysis like this: \r\n\r\n```shell\r\ncluster:~ user$ seqspark SingleStudy seqa.conf [spark-options]\r\n```\r\n\r\nAs with other Spark-based applications, you can specify useful Spark options like “num-executors” on command line. For more options in Spark, please refer to submitting-applications. In section Configuration, we will explain the options in the configuration file section by section. In section Examples, we will give several examples on how to use it in various scenarios.\r\n\r\n## Installation\r\n\r\n### Binary version\r\n\r\nSeqSpark is a Spark application written in Scala, so the binary is simply a jar file with a few assistant scripts. You can download the whole package from [here](http://seqspark.dizhang.org/seqspark.tar):\r\n\r\n```shell\r\nuser@server ~$ wget http://seqspark.dizhang.org/seqspark.tar\r\n```\r\n\r\nAfter you downloading the tar file, you can uncompress it:\r\n\r\n```shell\r\nuser@server: ~$ tar xf seqspark.tar\r\n```\r\n\r\nMove the folder to somewhere desirable:\r\n\r\n```shell\r\nuser@server: ~$ mv seqspark ~/software/\r\n```\r\n\r\nSet the path to your environment:\r\n\r\n```shell\r\nuser@server: ~$ echo \"PATH=~/software/seqspark:$PATH\" >> ~/.bashrc\r\n```\r\n\r\nThe last two steps are optional, which can usually help you organize your packages and faciliate the use.\r\n\r\nThis binary version only includes the program, you then need to download the databases:\r\n\r\n```shell\r\nuser@server: ~$ seqspark-db ref RefSeq,dbSNP\r\n```\r\n\r\nThe RefSeq and dbSNP databases will be downloaded to the remote ref folder of your HDFS.\r\n\r\n### Build from source\r\n\r\nTo build seqspark from source, you need `sbt`, which is available [here](http://www.scala-sbt.org/0.13/docs/Manual-Installation.html). And because we used one fortran program to calculate the multi-variate normal distribution, you also need `gfortran`, which should come with `gcc` on most linux distros.\r\n\r\nGet the source code:\r\n\r\n```shell\r\nuser@server: ~$ git clone https://github.com/zhangdi-devel/seqspark.git\r\n```\r\n\r\nIf you don't have git, just paste the URL to your web browser and go to the website to download the zip file.\r\n\r\nCompile the source and install:\r\n\r\n```shell\r\nuser@server: seqspark$ ./install --prefix ~/software/seqspark --db-dir ref \r\n```\r\n\r\nIf you have never run `sbt` or compiled `seqspark` before, it may take some time to download the dependencies. This `install` script will not only compile the source code, but also download RefSeq and dbSNP database files. For other prebuilt databases, you need to use the script `seqspark-db`. The CADD database is quite large (65GB), so it may take some time to finish. For a full description of the scripts, please refer to section Scripts. \r\n\r\n### Virtual machine demo\r\n\r\nWe built a virtual machine demo for you to play with SeqSpark. Please download this Vagrant [configuration file](https://seqspark.dizhang.org/Vagrantfile). You need Vagrant and VirtualBox installed on your host OS. Please check the Vagrant download [page](https://www.vagrantup.com/downloads.html) and the VirtualBox download [page](https://www.virtualbox.org/wiki/Downloads) for your platform (Mac, Windows, or Linux). Once you have them installed, just type `vagrant up` in the same folder containing the configuration file. Then you can log into the virtual machine by typing `vagrant ssh`.\r\n\r\nIn the virtual machine, you can run the demos of SeqSpark:\r\n\r\n```shell\r\nuser@sepspark: ~$ seqspark SingleStudy seqspark-demo.conf\r\n```\r\n\r\n## Configuration\r\n\r\nThe configuration file contains all the options of SeqSpark. \r\n\r\n### Single study\r\n\r\nUnder the root braces of the configuration file, you can set up general runtime options for a certain submission.\r\n\r\n```json\r\nproject = seqspark\r\nlocalDir = ${PWD}\r\ndbDir = seqspark_db\r\npipeline = [ qualityControl, association ]\r\n```\r\n\r\n### Meta analysis",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}